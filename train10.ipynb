{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "680b5527-a3b9-4f23-b246-8e36c246a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import clip\n",
    "    \n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "936b6aba-dfdc-438b-9d0b-c8e0b8efb744",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load('ViT-B/32', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d243bc-6c31-453f-97ab-65ec5fcadd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset_10 = \"/projectnb/ec523kb/projects/chopped/data/food101_10percent\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "train_dataset_10 = datasets.ImageFolder(path_dataset_10, transform=transform)\n",
    "dataloader_10 = DataLoader(train_dataset_10, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57d62ad5-85ff-4dd2-a5e4-ec52955fafc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
      "  (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (transformer): Transformer(\n",
      "    (resblocks): Sequential(\n",
      "      (0): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (6): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (7): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (8): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (9): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (10): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (11): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef5926ba-52cd-4cd4-b634-7a29285e84c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/ec523kb/students/chrisdc/.conda/envs/chopped/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/ec523kb/students/chrisdc/.conda/envs/chopped/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1699449183005/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "img, label = train_dataset_10[0]\n",
    "\n",
    "img = transforms.Resize((224, 224))(img)\n",
    "img = img.unsqueeze(0)\n",
    "img = img.to(device)\n",
    "img = img.half()\n",
    "print(img.shape)\n",
    "\n",
    "out = model.visual(img)\n",
    "print(out.shape)\n",
    "# fig, ax = plt.subplots(1, 3)\n",
    "# ax[0].imshow(img.permute(1, 2, 0))\n",
    "# print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ddca733-a224-44ae-bfc2-85f35d1dbea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipClassify(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vit = model.visual\n",
    "        self.classification_head = nn.Linear(512, 101)\n",
    "\n",
    "    def forward(x):\n",
    "        x = self.vit(x)\n",
    "        x = self.classification_head(x)\n",
    "        x = nn.Softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a85d7e-599a-4750-b695-d4b56ef0a2aa",
   "metadata": {},
   "source": [
    "## Fine Tune With Various LLRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "250a2edb-4ee5-43e2-9673-b5f23738e505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "vit.class_embedding\n",
      "vit.positional_embedding\n",
      "vit.proj\n",
      "vit.conv1.weight\n",
      "vit.ln_pre.weight\n",
      "vit.ln_pre.bias\n",
      "vit.transformer.resblocks.0.attn.in_proj_weight\n",
      "vit.transformer.resblocks.0.attn.in_proj_bias\n",
      "vit.transformer.resblocks.0.attn.out_proj.weight\n",
      "vit.transformer.resblocks.0.attn.out_proj.bias\n",
      "vit.transformer.resblocks.0.ln_1.weight\n",
      "vit.transformer.resblocks.0.ln_1.bias\n",
      "vit.transformer.resblocks.0.mlp.c_fc.weight\n",
      "vit.transformer.resblocks.0.mlp.c_fc.bias\n",
      "vit.transformer.resblocks.0.mlp.c_proj.weight\n",
      "vit.transformer.resblocks.0.mlp.c_proj.bias\n",
      "vit.transformer.resblocks.0.ln_2.weight\n",
      "vit.transformer.resblocks.0.ln_2.bias\n",
      "vit.transformer.resblocks.1.attn.in_proj_weight\n",
      "vit.transformer.resblocks.1.attn.in_proj_bias\n",
      "vit.transformer.resblocks.1.attn.out_proj.weight\n",
      "vit.transformer.resblocks.1.attn.out_proj.bias\n",
      "vit.transformer.resblocks.1.ln_1.weight\n",
      "vit.transformer.resblocks.1.ln_1.bias\n",
      "vit.transformer.resblocks.1.mlp.c_fc.weight\n",
      "vit.transformer.resblocks.1.mlp.c_fc.bias\n",
      "vit.transformer.resblocks.1.mlp.c_proj.weight\n",
      "vit.transformer.resblocks.1.mlp.c_proj.bias\n",
      "vit.transformer.resblocks.1.ln_2.weight\n",
      "vit.transformer.resblocks.1.ln_2.bias\n",
      "vit.transformer.resblocks.2.attn.in_proj_weight\n",
      "vit.transformer.resblocks.2.attn.in_proj_bias\n",
      "vit.transformer.resblocks.2.attn.out_proj.weight\n",
      "vit.transformer.resblocks.2.attn.out_proj.bias\n",
      "vit.transformer.resblocks.2.ln_1.weight\n",
      "vit.transformer.resblocks.2.ln_1.bias\n",
      "vit.transformer.resblocks.2.mlp.c_fc.weight\n",
      "vit.transformer.resblocks.2.mlp.c_fc.bias\n",
      "vit.transformer.resblocks.2.mlp.c_proj.weight\n",
      "vit.transformer.resblocks.2.mlp.c_proj.bias\n",
      "vit.transformer.resblocks.2.ln_2.weight\n",
      "vit.transformer.resblocks.2.ln_2.bias\n",
      "vit.transformer.resblocks.3.attn.in_proj_weight\n",
      "vit.transformer.resblocks.3.attn.in_proj_bias\n",
      "vit.transformer.resblocks.3.attn.out_proj.weight\n",
      "vit.transformer.resblocks.3.attn.out_proj.bias\n",
      "vit.transformer.resblocks.3.ln_1.weight\n",
      "vit.transformer.resblocks.3.ln_1.bias\n",
      "vit.transformer.resblocks.3.mlp.c_fc.weight\n",
      "vit.transformer.resblocks.3.mlp.c_fc.bias\n",
      "vit.transformer.resblocks.3.mlp.c_proj.weight\n",
      "vit.transformer.resblocks.3.mlp.c_proj.bias\n",
      "vit.transformer.resblocks.3.ln_2.weight\n",
      "vit.transformer.resblocks.3.ln_2.bias\n",
      "vit.transformer.resblocks.4.attn.in_proj_weight\n",
      "vit.transformer.resblocks.4.attn.in_proj_bias\n",
      "vit.transformer.resblocks.4.attn.out_proj.weight\n",
      "vit.transformer.resblocks.4.attn.out_proj.bias\n",
      "vit.transformer.resblocks.4.ln_1.weight\n",
      "vit.transformer.resblocks.4.ln_1.bias\n",
      "vit.transformer.resblocks.4.mlp.c_fc.weight\n",
      "vit.transformer.resblocks.4.mlp.c_fc.bias\n",
      "vit.transformer.resblocks.4.mlp.c_proj.weight\n",
      "vit.transformer.resblocks.4.mlp.c_proj.bias\n",
      "vit.transformer.resblocks.4.ln_2.weight\n",
      "vit.transformer.resblocks.4.ln_2.bias\n",
      "vit.transformer.resblocks.5.attn.in_proj_weight\n",
      "vit.transformer.resblocks.5.attn.in_proj_bias\n",
      "vit.transformer.resblocks.5.attn.out_proj.weight\n",
      "vit.transformer.resblocks.5.attn.out_proj.bias\n",
      "vit.transformer.resblocks.5.ln_1.weight\n",
      "vit.transformer.resblocks.5.ln_1.bias\n",
      "vit.transformer.resblocks.5.mlp.c_fc.weight\n",
      "vit.transformer.resblocks.5.mlp.c_fc.bias\n",
      "vit.transformer.resblocks.5.mlp.c_proj.weight\n",
      "vit.transformer.resblocks.5.mlp.c_proj.bias\n",
      "vit.transformer.resblocks.5.ln_2.weight\n",
      "vit.transformer.resblocks.5.ln_2.bias\n",
      "vit.transformer.resblocks.6.attn.in_proj_weight\n",
      "vit.transformer.resblocks.6.attn.in_proj_bias\n",
      "vit.transformer.resblocks.6.attn.out_proj.weight\n",
      "vit.transformer.resblocks.6.attn.out_proj.bias\n",
      "vit.transformer.resblocks.6.ln_1.weight\n",
      "vit.transformer.resblocks.6.ln_1.bias\n",
      "vit.transformer.resblocks.6.mlp.c_fc.weight\n",
      "vit.transformer.resblocks.6.mlp.c_fc.bias\n",
      "vit.transformer.resblocks.6.mlp.c_proj.weight\n",
      "vit.transformer.resblocks.6.mlp.c_proj.bias\n",
      "vit.transformer.resblocks.6.ln_2.weight\n",
      "vit.transformer.resblocks.6.ln_2.bias\n",
      "vit.transformer.resblocks.7.attn.in_proj_weight\n",
      "vit.transformer.resblocks.7.attn.in_proj_bias\n",
      "vit.transformer.resblocks.7.attn.out_proj.weight\n",
      "vit.transformer.resblocks.7.attn.out_proj.bias\n",
      "vit.transformer.resblocks.7.ln_1.weight\n",
      "vit.transformer.resblocks.7.ln_1.bias\n",
      "vit.transformer.resblocks.7.mlp.c_fc.weight\n",
      "vit.transformer.resblocks.7.mlp.c_fc.bias\n",
      "vit.transformer.resblocks.7.mlp.c_proj.weight\n",
      "vit.transformer.resblocks.7.mlp.c_proj.bias\n",
      "vit.transformer.resblocks.7.ln_2.weight\n",
      "vit.transformer.resblocks.7.ln_2.bias\n",
      "vit.transformer.resblocks.8.attn.in_proj_weight\n",
      "vit.transformer.resblocks.8.attn.in_proj_bias\n",
      "vit.transformer.resblocks.8.attn.out_proj.weight\n",
      "vit.transformer.resblocks.8.attn.out_proj.bias\n",
      "vit.transformer.resblocks.8.ln_1.weight\n",
      "vit.transformer.resblocks.8.ln_1.bias\n",
      "vit.transformer.resblocks.8.mlp.c_fc.weight\n",
      "vit.transformer.resblocks.8.mlp.c_fc.bias\n",
      "vit.transformer.resblocks.8.mlp.c_proj.weight\n",
      "vit.transformer.resblocks.8.mlp.c_proj.bias\n",
      "vit.transformer.resblocks.8.ln_2.weight\n",
      "vit.transformer.resblocks.8.ln_2.bias\n",
      "vit.transformer.resblocks.9.attn.in_proj_weight\n",
      "vit.transformer.resblocks.9.attn.in_proj_bias\n",
      "vit.transformer.resblocks.9.attn.out_proj.weight\n",
      "vit.transformer.resblocks.9.attn.out_proj.bias\n",
      "vit.transformer.resblocks.9.ln_1.weight\n",
      "vit.transformer.resblocks.9.ln_1.bias\n",
      "vit.transformer.resblocks.9.mlp.c_fc.weight\n",
      "vit.transformer.resblocks.9.mlp.c_fc.bias\n",
      "vit.transformer.resblocks.9.mlp.c_proj.weight\n",
      "vit.transformer.resblocks.9.mlp.c_proj.bias\n",
      "vit.transformer.resblocks.9.ln_2.weight\n",
      "vit.transformer.resblocks.9.ln_2.bias\n",
      "vit.transformer.resblocks.10.attn.in_proj_weight\n",
      "vit.transformer.resblocks.10.attn.in_proj_bias\n",
      "vit.transformer.resblocks.10.attn.out_proj.weight\n",
      "vit.transformer.resblocks.10.attn.out_proj.bias\n",
      "vit.transformer.resblocks.10.ln_1.weight\n",
      "vit.transformer.resblocks.10.ln_1.bias\n",
      "vit.transformer.resblocks.10.mlp.c_fc.weight\n",
      "vit.transformer.resblocks.10.mlp.c_fc.bias\n",
      "vit.transformer.resblocks.10.mlp.c_proj.weight\n",
      "vit.transformer.resblocks.10.mlp.c_proj.bias\n",
      "vit.transformer.resblocks.10.ln_2.weight\n",
      "vit.transformer.resblocks.10.ln_2.bias\n",
      "vit.transformer.resblocks.11.attn.in_proj_weight\n",
      "vit.transformer.resblocks.11.attn.in_proj_bias\n",
      "vit.transformer.resblocks.11.attn.out_proj.weight\n",
      "vit.transformer.resblocks.11.attn.out_proj.bias\n",
      "vit.transformer.resblocks.11.ln_1.weight\n",
      "vit.transformer.resblocks.11.ln_1.bias\n",
      "vit.transformer.resblocks.11.mlp.c_fc.weight\n",
      "vit.transformer.resblocks.11.mlp.c_fc.bias\n",
      "vit.transformer.resblocks.11.mlp.c_proj.weight\n",
      "vit.transformer.resblocks.11.mlp.c_proj.bias\n",
      "vit.transformer.resblocks.11.ln_2.weight\n",
      "vit.transformer.resblocks.11.ln_2.bias\n",
      "vit.ln_post.weight\n",
      "vit.ln_post.bias\n",
      "classification_head.weight\n",
      "classification_head.bias\n"
     ]
    }
   ],
   "source": [
    "parameters = []\n",
    "net = ClipClassify().to(device)\n",
    "print(type(net.vit.transformer.resblocks[11].named_parameters()))\n",
    "parameters += [{'params': 3}]\n",
    "\n",
    "layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "layers = [name for name, param in net.named_parameters()]\n",
    "for layer in layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8678a7e2-1644-4a82-bd74-7db8a132326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of ClipClassify(\n",
      "  (vit): VisionTransformer(\n",
      "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
      "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (transformer): Transformer(\n",
      "      (resblocks): Sequential(\n",
      "        (0): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (6): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (7): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (8): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (9): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (10): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (11): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (classification_head): Linear(in_features=512, out_features=101, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "clip_classify = ClipClassify().to(device)\n",
    "print(clip_classify.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ddd791-76c9-4859-b095-3fe88f1213ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss\n",
    "clip_classify = ClipClassify().to(device)\n",
    "optimizer = optim.AdamW(clip_classify.parameters(), )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
