{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Necessary Imports Needed to Run Model"
      ],
      "metadata": {
        "id": "FYEOdkM3kdkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import random\n",
        "import copy\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from sklearn.utils import shuffle\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager\n",
        "from collections import OrderedDict\n",
        "\n",
        "#XCeption:\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.applications import efficientnet\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.applications.xception import Xception\n"
      ],
      "metadata": {
        "id": "Ve_uMRiaehEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive and Extract Necessary Folders"
      ],
      "metadata": {
        "id": "4T8b0MkKkiut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSQl0lsDdUL4",
        "outputId": "5c33ad1c-9995-4fc7-f7fc-7c05cae43755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwXMaGmS0vEa",
        "outputId": "5739555f-c7c9-4445-b2b1-305114d6f625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define which percent data you want to use\n",
        "data_folder = '100percent'"
      ],
      "metadata": {
        "id": "USiTH5wmkoEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DS-UcA-Pb0BO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d177af48-b3d0-45e5-cb45-e1c44168a401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101\n"
          ]
        }
      ],
      "source": [
        "# Unzipping the Food-101 dataset - training\n",
        "zip_file_path = '/content/drive/MyDrive/EC523-Project/data/zip/food101_' + data_folder + '.zip'\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/train')\n",
        "\n",
        "zip_file_path = '/content/drive/MyDrive/EC523-Project/data/zip/food101_test.zip'\n",
        "# Unzipping the Food-101 dataset\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/train')\n",
        "\n",
        "classes = sorted(os.listdir('/content/train/food101_' + data_folder + '/train'))\n",
        "print(len(classes))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_path = '/content/train/food101_' + data_folder + '/train'\n",
        "test_images_path = '/content/train/food101_test'\n",
        "\n",
        "# Lists to store training and testing data paths\n",
        "train_data = []\n",
        "test_data = []\n",
        "\n",
        "\n",
        "for food_category in os.listdir(train_images_path):\n",
        "    category_path = os.path.join(train_images_path, food_category)\n",
        "    images = os.listdir(category_path)\n",
        "    train_images = images[:]\n",
        "\n",
        "    # Add image paths to the train and test lists\n",
        "    train_data.extend([f\"{food_category}/{img}\" for img in train_images])\n",
        "\n",
        "for food_category in os.listdir(test_images_path):\n",
        "    category_path = os.path.join(test_images_path, food_category)\n",
        "    images = os.listdir(category_path)\n",
        "    test_images = images[:]\n",
        "    # Add image paths to the train and test lists\n",
        "    test_data.extend([f\"{food_category}/{img}\" for img in test_images])"
      ],
      "metadata": {
        "id": "V_l8Ln0QfsQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Meta Folder to Emulate Pytorch Dataset"
      ],
      "metadata": {
        "id": "ix2ksLkPlJNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory_path = '/content/train/meta'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(directory_path):\n",
        "    os.makedirs(directory_path)\n",
        "    print(f\"Directory '{directory_path}' created.\")\n",
        "\n",
        "# File path for the file to create within the directory\n",
        "file_path = os.path.join(directory_path, 'train.txt')\n",
        "file_path = os.path.join(directory_path, 'test.txt')\n",
        "file_path = os.path.join(directory_path, 'classes.txt')\n",
        "\n",
        "\n",
        "# Write the train and test data to files\n",
        "with open('/content/train/meta/train.txt', 'w') as f:\n",
        "    for item in train_data:\n",
        "        f.write(\"%s\\n\" % item)\n",
        "\n",
        "with open('/content/train/meta/test.txt', 'w') as f:\n",
        "    for item in test_data:\n",
        "        f.write(\"%s\\n\" % item)\n",
        "\n",
        "with open('/content/train/meta/classes.txt', 'w') as f:\n",
        "    for item in classes:\n",
        "        f.write(\"%s\\n\" % item)\n",
        "\n",
        "# Display the first 5 lines of each file as a sample\n",
        "print(\"Testing images\")\n",
        "print(\"\\n\".join(test_data[:5]))\n",
        "print(\"\\nTraining images\")\n",
        "print(\"\\n\".join(train_data[:5]))"
      ],
      "metadata": {
        "id": "QcMb1aSWlIdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check Meta Folder\n",
        "os.listdir('/content/train/meta')"
      ],
      "metadata": {
        "id": "BGNSEDNalPSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataframe Prep and Data Augmentation"
      ],
      "metadata": {
        "id": "vIAWd-Prlv2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/train/meta/train.txt', header = None, names=['path'])\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "xJpqF6y_WYHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('/content/train/meta/test.txt', header = None, names=['path'])\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "yLhFjkWUWu-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spliter(data, class_or_id='id'):\n",
        "    if class_or_id.upper() == 'CLASS':\n",
        "        output = data.split('/')[0]\n",
        "\n",
        "    else:\n",
        "        output = data.split('/')[-1]\n",
        "    return output"
      ],
      "metadata": {
        "id": "c0FWpMInW1eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['label'] = train_df['path'].map(lambda x: spliter(data = x, class_or_id = 'Class'))\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "-8gxGmPZW4cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['idx'] = train_df['path'].map(lambda x: spliter(x))\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "03l2FMrTW67X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['label'] = test_df['path'].map(lambda x: spliter(x, 'class'))\n",
        "test_df['idx'] = test_df['path'].map(lambda x: spliter(x))\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "0f-ubYnKW-BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mini_101 = train_df['label'].unique()[:101]\n",
        "mini_101 = [f.upper() for f in mini_101]\n",
        "mini_101"
      ],
      "metadata": {
        "id": "4H4GoQMiXA-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(label):\n",
        "    if label.upper() in mini_101:\n",
        "        return label\n",
        "    else:\n",
        "        return 'Others'"
      ],
      "metadata": {
        "id": "B5Hs9N_lXGtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['label'] = train_df['label'].map(lambda x: prepare_data(x))\n",
        "test_df['label'] = test_df['label'].map(lambda x: prepare_data(x))"
      ],
      "metadata": {
        "id": "5zRvYc1qXJCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['label'].unique()"
      ],
      "metadata": {
        "id": "TgS1wiATXLJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_exact_path_train(path):\n",
        "    return '/content/train/food101_' + data_folder + '/train/'+path\n",
        "\n",
        "def add_exact_path_test(path):\n",
        "    return '/content/train/food101_test/'+path"
      ],
      "metadata": {
        "id": "RQlk9-CiXOFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['path'] = train_df[['path']].apply(add_exact_path_train, axis=1)\n",
        "test_df['path'] = test_df[['path']].apply(add_exact_path_test, axis=1)\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "8hsGATqlXQGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "img = plt.imread(train_df['path'].iloc[0])\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "8klcn4P8Xuqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "wYxTO_zBb9B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "test_gen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "B_huHeesb_w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = datagen.flow_from_dataframe(dataframe = train_df, directory=None, x_col='path', y_col='label',\n",
        "    weight_col=None, target_size=(256, 256), color_mode='rgb',\n",
        "    classes=None, class_mode='categorical', batch_size=32, shuffle=True, validate_filenames=False)"
      ],
      "metadata": {
        "id": "3QbwFjMucEI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_gen = datagen.flow_from_dataframe(dataframe = test_df, directory=None, x_col='path', y_col='label',\n",
        "    weight_col=None, target_size=(256, 256), color_mode='rgb',\n",
        "    classes=None, class_mode='categorical', batch_size=32, shuffle=True, validate_filenames=False)"
      ],
      "metadata": {
        "id": "-4tUr0h5cJY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "d3NatkgmmfZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xception = Xception(weights='imagenet', include_top=False)\n",
        "x = Xception.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256,activation='relu')(x)\n",
        "# x = Dropout(0.4)(x)\n",
        "x = Dense(128,activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "predictions = Dense(101, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=Xception.input, outputs=predictions)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BfgsFexDctvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_gen,\n",
        "                              steps_per_epoch = len(train_gen) // 32,\n",
        "                    epochs=300,\n",
        "                    verbose=1)\n"
      ],
      "metadata": {
        "id": "PSp_O9IZc3QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "Ty6XrQojmm4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.evaluate(test_gen, batch_size=32)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "Sb5SUmEWdBed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy plot\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Training Accuracy'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PCNxoT6edGJx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}